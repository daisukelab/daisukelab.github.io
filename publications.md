# Publications

This page lists my full publication record, categorized into journals, international conferences, invited talks, invited articles, and other activities.

---

## Journal Articles
1. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   *"Masked Modeling Duo: Towards a Universal Audio Pre-Training Framework,"*  
   **IEEE/ACM Trans. Audio, Speech, Language Process.**, vol. 32, pp. 2391–2406, 2024. [(URL)](https://ieeexplore.ieee.org/document/10502167)
2. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   *"BYOL for Audio: Exploring Pre-trained General-purpose Audio Representations,"*  
   **IEEE/ACM Trans. Audio, Speech, Language Process.**, vol. 31, pp. 137–151, 2023. [(URL)](https://ieeexplore.ieee.org/document/9944865)

#### Co-authored
- S. Kobayashi, R. Kuwakubo, S. Matsui, Y. Otani, X. Zhang, D. Niizumi,  
  *"The Morandi Room: Entering the World of Morandi’s Paintings Through Machine Learning,"*  
  **Advances in Artificial Intelligence**, pp. 145–156, 2021. [(URL)](https://link.springer.com/chapter/10.1007/978-3-030-73113-7_13)

---

## International Conferences

### First-author papers

## International Conference Proceedings (First Author)
1. D. Niizumi, D. Takeuchi, M. Yasuda, B. T. Nguyen, Y. Ohishi, N. Harada,  
   "Assessing the Utility of Audio Foundation Models for Heart and Respiratory Sound Analysis,"  
   *EMBC*, 2025.
2. D. Niizumi, D. Takeuchi, M. Yasuda, B. T. Nguyen, Y. Ohishi, N. Harada,  
   "Towards Pre-training an Effective Respiratory Audio Foundation Model,"  
   *Interspeech*, 2025.
3. D. Niizumi, D. Takeuchi, M. Yasuda, B. T. Nguyen, Y. Ohishi, N. Harada,  
   "Probin M2D: Technical Report for the ICME 2025 Audio Encoder Capability Challenge,"  
   *ICME Audio Encoder Capability Challenge*, 2025.
4. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   "Exploring Pre-trained General-purpose Audio Representations for Heart Murmur Detection,"  
   *EMBC*, 2024.
5. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, M. Yasuda, S. Tsubaki, K. Imoto,  
   "M2D-CLAP: Masked Modeling Duo Meets CLAP for Learning General-purpose Audio-Language Representation,"  
   *Interspeech*, 2024.
6. D. Niizumi, N. Harada, M. Yasuda, Y. Ohishi, D. Takeuchi, M. Yasuda,  
   "ToyADMOS2#: Yet Another Dataset for the DCASE2024 Challenge Task 2 First-Shot Anomalous Sound Detection,"  
   *DCASE*, 2024.
7. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   "Masked Modeling Duo: Learning Representations by Encouraging Both Networks to Model the Input,"  
   *ICASSP*, 2023.
8. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   "Masked Modeling Duo for Speech: Specializing General-Purpose Audio Representation to Speech using Denoising Distillation,"  
   *Interspeech*,.
9. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
   "Masked Spectrogram Modeling using Masked Autoencoders for Learning General-purpose Audio Representation,"  
   *HEAR: Holistic Evaluation of Audio Representations (NeurIPS 2021 Competition)*, vol. 166, pp. 1–24, 2022.
10. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
    "Composing General Audio Representation by Fusing Multilayer Features of a Pre-trained Model,"  
    *EUSIPCO*, 2022.
11. D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Kashino,  
    "BYOL for Audio: Self-Supervised Learning for General-Purpose Audio Representation,"  
    *International Joint Conference on Neural Networks (IJCNN)*, 2021.

### Co-authored 
1.	B. T. Nguyen, D. Takeuchi, M. Yasuda, D. Niizumi, Y. Ohishi, N. Harada,
    “Collision-less and Balanced Sampling for Language-Queried Audio Source Separation,”
    *ICASSP*, 2025.
2.	C. Hernandez-Olivan, M. Delcroix, T. Ochiai, D. Niizumi, N. Tawara, T. Nakatani, S. Araki,
    "SoundBeam meets M2D: Target Sound Extraction with Audio Foundation Model,"
  	*ICASSP*, 2025.
3.	D. Takeuchi, B. T. Nguyen, M. Yasuda, Y. Ohishi, D. Niizumi, N. Harada,
    “CLAP-ART: Automated Audio Captioning with Semantic-rich Audio Representation Tokenizer,”
  	*Interspeech*, 2025.
4.	B. T. Nguyen, M. Yasuda, D. Takeuchi, D. Niizumi, Y. Ohishi, N. Harada,
    “Baseline Systems and Evaluation Metrics for Spatial Semantic Segmentation of Sound Scenes,”
  	*EUSIPCO*, 2025 (to appear).
5.	T. Nishida, N. Harada, D. Niizumi, D. Albertini, R. Sannino, S. Pradolini, F. Augusti, K. Imoto, K. Dohi, H. Purohit, T. Endo, Y. Kawaguchi,
    “Description and Discussion on DCASE 2025 Challenge Task 2: First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring,”
  	*DCASE*, 2025 (to appear).
6.	M. Yasuda, B. T. Nguyen, N. Harada, R. Serizel, M. Mishra, M. Delcroix, S. Araki, D. Takeuchi, D. Niizumi, Y. Ohishi, T. Nakatani, T. Kawamura, N. Ono,
    "Description and Discussion on DCASE 2025 Challenge Task 4: Spatial Semantic Segmentation of Sound Scenes,"
    *DCASE*, 2025 (to appear).
7.	D. Takeuchi, M. Yasuda, D. Niizumi, N. Harada,
    “Towards Learning a Difference-aware General-purpose Audio Representation,”
   	*DCASE*, 2024.
8.	S. Tsubaki, D. Niizumi, D. Takeuchi, Y. Ohishi, N. Harada, K. Imoto,
    “Refining knowledge transfer on audio-image temporal agreement for audio-text cross retrieval,”
   	*EUSIPCO*, 2024.
9.	T. Nishida, N. Harada, D. Niizumi, D. Albertini, R. Sannino, S. Pradolini, F. Augusti, K. Imoto, K. Dohi, H. Purohit, T. Endo, Y. Kawaguchi,
    “Description and Discussion on DCASE 2024 Challenge Task 2: First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring,”
   	*DCASE*, 2024.
10.	N. Harada, D. Niizumi, Y. Ohishi, D. Takeuchi, M. Yasuda,
    “First-shot anomaly sound detection for machine condition monitoring: A domain generalization baseline,”
   	*EUSIPCO*, 2023.
11.	N. Harada, D. Niizumi, Y. Ohishi, D. Takeuchi, M. Yasuda,
    “ToyADMOS2+: Detailed description of newly recorded ToyADMOS data and benchmark results of the First-shot ASD baseline,”
   	*DCASE*, 2023.
12.	D. Takeuchi, Y. Ohishi, D. Niizumi, N. Harada, K. Kashino,
    “Audio Difference Captioning Utilizing Similarity-Discrepancy Disentanglement,”
   	*DCASE*, 2023.
13.	K. Dohi, K. Imoto, N. Harada, D. Niizumi, Y. Koizumi, T. Nishida, H. Purohit, et. al.,
    “Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring,”
   	*DCASE*, 2023.
14.	B. Liu, S. Zhang, D. Takeuchi, D. Niizumi, N. Harada, S. Makino,
    “MASKED MODELING DUO VISION TRANSFORMER WITH MULTI-LAYER FEATURE FUSION ON RESPIRATORY SOUND CLASSIFICATION,”
   	*DCASE*, 2023.
15.	H. Xing, S. Zhang, D. Takeuchi, D. Niizumi, N. Harada, S. Makino,
    “Enhancing Spectrogram for Audio Classification Using Time-Frequency Enhancer,”
   	*APSIPA*, 2023.
16.	D. Takeuchi, Y. Ohishi, D. Niizumi, N. Harada, K. Kashino,
    "Introducing Auxiliary Text Query-modifier to Content-based Audio Retrieval,"
   	*Interspeech*, 2022.
17.	Y. Ohishi, M. Delcroix, T. Ochiai, S. Araki, D. Takeuchi, D. Niizumi, A. Kimura, N. Harada, and K. Kashino,
    "ConceptBeam: Concept driven target speech extraction,"
   	*ACM-MM*, 2022.
18.	K. Dohi, K. Imoto, N. Harada, D. Niizumi, Y. Koizumi, T. Nishida, H. Purohit, T. Endo, M. Yamamoto, and Y. Kawaguchi,
    "Description and discussion on DCASE 2022 challenge task 2: Unsupervised anomalous sound detection for machine condition monitoring applying domain generalization techniques,"
   	*DCASE*, 2022.
19.	N. Harada, D. Niizumi, D. Takeuchi, Y. Ohishi, M. Yasuda, and S. Saito,
    "ToyADMOS2: Another Dataset of Miniature-Machine Operating Sounds for Anomalous Sound Detection under Domain Shift Conditions,"
   	*DCASE*, 2021.
20.	Y. Kawaguchi, K. Imoto, Y. Koizumi, N. Harada, D. Niizumi, K. Dohi, R. Tanabe, H. Purohit, and T. Endo,
    "Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions,"
   	*DCASE*, 2021
21.	S. Gharib, H. Derrar, D. Niizumi, T. Senttula, J. Tommola, T. Heittola, T. Virtanen, H. Huttunen,
    "Acoustic scene classification: A competition review,"
   	*MLSP*, 2018

---

## Invited Talks
- Daisuke Niizumi, *"AI that learns to listen on its own -- Advancing self-supervised audio representation toward cutting-edge sound understanding with large language models"*,  
  NTT Communication Science Laboratories OPEN HOUSE 2025, 2025.  [(URL)](https://www.kecl.ntt.co.jp/openhouse/2025/lecture_04_en.html)
- Daisuke Niizumi, *"BYOL for Audio: Exploring Pre-Trained General-Purpose Audio Representations,"*  
  IEEE Signal Processing Society Webinar, 2024.  [(URL)](https://signalprocessingsociety.org/blog/sps-webinar-byol-audio-exploring-pre-trained-general-purpose-audio-representations)
- 仁泉 大輔, *"音を扱いやすくする汎用音響信号表現について,"*  
  日本音響学会, 2022.  [(Slides)](https://asj-fresh.acoustics.jp/wordpress/wp-content/uploads/2022/09/asj_beginners_seminar_2022a_niizumi.pdf)
- 仁泉 大輔, *"汎用音響信号表現の発展について,"*  
  Tokyo BISH Bash #07, 2022. [(Slides)](https://speakerdeck.com/daisukelab_cs/fan-yong-yin-xiang-xin-hao-biao-xian-falsefa-zhan-nituite-at-tokyobishbash-number-07)

---

## Invited Articles
- 仁泉 大輔, *“一般の音を学習する音響信号表現の最前線,”*  
  **日本音響学会誌**, 80 (12), pp. 649–657, 2024. [(URL)](https://www.jstage.jst.go.jp/article/jasj/80/12/80_649/_article/-char/en)

---

## Other Activities
- Reviewer: ICASSP, Interspeech, IEEE JSTSP, TASLP, etc.
- Active participation in the **DCASE Challenge** and workshops.  

---

[← Back to Home](index.md)
